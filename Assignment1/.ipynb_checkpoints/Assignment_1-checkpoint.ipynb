{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZO7huXHVr6JI"
   },
   "source": [
    "# Assignment 1: Tri-gram Language Model and NER Tagging\n",
    "Welcome to your first assignment of CSE-476! Your goal in this assignment is to implement a trigram language model, and then use its output as features to train a NER model using provided implementations of a perceptron model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "EjLtKYOJrzr2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Initial loading of the data file and the NLTK tokenizer.\n",
    "Please do not modify this section.\n",
    "You need to run this first.\n",
    "'''\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import defaultdict\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('brown')\n",
    "\n",
    "# load brown corpus\n",
    "def load_corpus():\n",
    "    corpus = list(brown.sents())\n",
    "    for i in range(len(corpus)):\n",
    "        corpus[i] = \" \".join(corpus[i])\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Km83umKcs6ef"
   },
   "source": [
    "## Task 1: Implement the TrigramLM class.\n",
    "\n",
    "You are provided with some starting code. You are free to modify the starting code, as long as you meet all requirements as specified by the comments below, and your class can be used in the following way:\n",
    "\n",
    "\n",
    "```\n",
    "lm = TrigramLM(\"vocab.txt\")\n",
    "lm.train()\n",
    "ranking = lm.next_word_ranking(\"this is a\")\n",
    "# Expected format of 'ranking':\n",
    "# [(\"good\", 0.04), (\"matter\", 0.03)....]\n",
    "```\n",
    "\n",
    "A few reviews of knowledge points:\n",
    "\n",
    "- 1: Unknown tokens are tokens that are not in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "fRtLKFQ3K14a"
   },
   "outputs": [],
   "source": [
    "class TrigramLM:\n",
    "\n",
    "    def __init__(self, vocab_file):\n",
    "        self.vocabulary = []\n",
    "        self.bigram_count_table = defaultdict(int)\n",
    "        '''\n",
    "        TODO\n",
    "        Other than the given bigram_count_table, what else would you need?\n",
    "        '''\n",
    "        self.trigram_count_table = defaultdict(int)\n",
    "        self.tokens = list()\n",
    "        self.start_vocab = \"<start>\"\n",
    "        self.end_vocab = \"<end>\"\n",
    "        self.unknown_vocab = \"<UNK>\"\n",
    "        self.load_vocab(vocab_file)\n",
    "\n",
    "    def load_vocab(self, vocab_file):\n",
    "        with open(vocab_file, 'r') as f:\n",
    "            for line in f:\n",
    "                self.vocabulary.append(line.strip())\n",
    "        self.vocabulary.append(self.unknown_vocab)\n",
    "        self.vocabulary.append(self.start_vocab)\n",
    "        self.vocabulary.append(self.end_vocab)\n",
    "        print(f\"vocab loaded, size = {len(self.vocabulary)}\")\n",
    "\n",
    "    '''\n",
    "    TODO\n",
    "    Implement the tokenize function.\n",
    "    @text is a string, e.g., text=\"Today is a good day\"\n",
    "    Return a list of strings of tokens, such as [\"today\", \"is\"...]\n",
    "    1. You MUST use NLTK's word_tokenize() function to split text into tokens.\n",
    "    2. You MUST implement a uncased LM. That is, the vocabularies in the given file are all lower-cased. You should lower-case all tokens here too.\n",
    "    3. Think about what do you need to do with unknown_vocab?\n",
    "    '''\n",
    "    def tokenize(self, text):\n",
    "        tokens = word_tokenize(text)\n",
    "        tokens = [token.lower() if token.lower() in self.vocabulary else self.unknown_vocab for token in tokens]\n",
    "        # Your code here.\n",
    "        return tokens\n",
    "\n",
    "    '''\n",
    "    TODO\n",
    "    Finish implementing the training function.\n",
    "    This function takes the corpus, and iteratively build all counts that the model may need to rank next words.\n",
    "    Think about what do you need to do with the start_vocab and end_vocab when loading data?\n",
    "    '''\n",
    "    def train(self):\n",
    "        corpus = load_corpus()\n",
    "        print(f\"corpus loaded, size = {len(corpus)}\")\n",
    "\n",
    "        # Your code here.\n",
    "        for i in corpus:\n",
    "            tokens = self.tokenize(i)\n",
    "            tokens = [self.start_vocab, self.start_vocab] + tokens + [self.end_vocab]\n",
    "\n",
    "            for j in range(len(tokens)-2):\n",
    "                t1, t2, t3 = tokens[j], tokens[j+1], tokens[j+2]\n",
    "                self.bigram_count_table[f\"{t1}, {t2}\"] += 1\n",
    "                self.trigram_count_table[f\"{t1}, {t2}, {t3}\"] += 1\n",
    "\n",
    "    '''\n",
    "    Implement the function that produces a list of top_n next words, given 'prior_context', with their probabilties.\n",
    "    @prior_context: a string of the current context, e.g., \"This is a\", and the function tries to predict the next word.\n",
    "    @top_n: returns the top-N most likely words.\n",
    "    Return a list of top_n words with their probabilties, in the format of [(\"good\", 0.04), (\"matter\", 0.03)....]\n",
    "    Think about what do you need to do for start_vocab and end_vocab?\n",
    "    '''\n",
    "    def next_word_ranking(self, prior_context, top_n=10):\n",
    "        # Your code here.\n",
    "        words = self.tokenize(prior_context)\n",
    "        bigram = None\n",
    "        \n",
    "        if len(words) >= 2:\n",
    "            bigram = words[-2:]\n",
    "        else:\n",
    "            bigram = [self.start_vocab]*(2-len(words)) + words\n",
    "\n",
    "        words_ranking = list()\n",
    "        context_bigram = self.bigram_count_table.get(f\"{bigram[0]}, {bigram[1]}\", 0)\n",
    "\n",
    "        if context_bigram > 0:\n",
    "            for word in self.vocabulary:\n",
    "                trigram = bigram + [word]\n",
    "                context_trigram = self.trigram_count_table.get(f\"{bigram[0]}, {bigram[1]}, {word}\", 0)\n",
    "                prob = context_trigram/context_bigram\n",
    "                words_ranking.append([word, prob])\n",
    "            words_ranking.sort(key=lambda x: (x[1], x[0]))\n",
    "            words_ranking.reverse()\n",
    "        else:\n",
    "            words_ranking = words_ranking\n",
    "\n",
    "        return words_ranking[:top_n]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PciU_xmPwiBp"
   },
   "source": [
    "## Task 2: Using the TrigramLM Predictions as Feature for NER.\n",
    "You are given a data loading helper function that loads the training data for NER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "1_Z-tMufPljf"
   },
   "outputs": [],
   "source": [
    "# !pip install datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "'''\n",
    "Loading NER training data.\n",
    "Please do not modify this section.\n",
    "'''\n",
    "\n",
    "def load_conll2003(split):\n",
    "    # ignore other tags\n",
    "    NER_tags={\n",
    "        0: \"O\",\n",
    "        1: \"B-PER\",\n",
    "        2: \"I-PER\",\n",
    "        3: \"B-ORG\",\n",
    "        4: \"I-ORG\",\n",
    "        5: \"B-LOC\",\n",
    "        6: \"I-LOC\",\n",
    "    }\n",
    "    dataset = load_dataset(\"eriktks/conll2003\", trust_remote_code=True)\n",
    "    data = []\n",
    "    for text in dataset[split]:\n",
    "        if len(data) > 10000:\n",
    "            break\n",
    "        for i in range(len(text[\"tokens\"])):\n",
    "            token = text[\"tokens\"][i]\n",
    "            tag = text[\"ner_tags\"][i]\n",
    "            if tag not in NER_tags:\n",
    "                tag = NER_tags[0]\n",
    "            else:\n",
    "                tag = NER_tags[tag]\n",
    "            data.append((token, tag))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H98NagxxxcQw"
   },
   "source": [
    "You are asked to finish implementing the NERTagger class. You can modify the contents in this class, as long as you meet the requirements specified by the comments below, and your NERTagger can be used as\n",
    "\n",
    "```\n",
    "lm = TrigramLM(\"vocab.txt\")\n",
    "lm.train()\n",
    "tagger = NERTagger(lm)\n",
    "tagger.train()\n",
    "ner_output = tagger.predict(\"John works at Microsoft and he loves it.\")\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "A1iRSyV7WX_q"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_training_data():\n",
    "    return load_conll2003(\"train\")\n",
    "\n",
    "\n",
    "class NERTagger:\n",
    "    def __init__(self, trained_lm):\n",
    "        self.lm = trained_lm\n",
    "        # For more documention on this usage, refer to\n",
    "        # https://scikit-learn.org/dev/modules/generated/sklearn.pipeline.make_pipeline.html\n",
    "        self.model = make_pipeline(DictVectorizer(), Perceptron(max_iter=1000, early_stopping=True), verbose=True)\n",
    "\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    Trains the perceptron model on the training data.\n",
    "    You will need to implement the missing part that extract the features labels based on the training data.\n",
    "    \"\"\"\n",
    "    def train(self):\n",
    "        # training_data returns a list of (token, label) tuples.\n",
    "        training_data = get_training_data()\n",
    "        features = []\n",
    "        labels = []\n",
    "        for i in range(len(training_data)):\n",
    "            context = \"\" if i < 3 else f\"{training_data[i-2][0]} {training_data[i-1][0]}\"\n",
    "            word, label = training_data[i]\n",
    "            feature = self._extract_features(context, word) # Your code here\n",
    "            features.append(feature)\n",
    "            labels.append(label)\n",
    "\n",
    "        self.model.fit(features, labels)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    Extracts features for the perceptron model.\n",
    "    The features include:\n",
    "    1) the top ten predictions (unordered) of the current word based on the context from your trained TrigramLM\n",
    "    2) the current word\n",
    "    Assume the context is \"Jeff lives in\" and the current_word is \"Japan\", and TrigramLM predict the top next words to be [\"us\", \"england\", ...]\n",
    "    The features should include \"us_in_next_word\": True, \"england_in_next_word\": True, ..., \"current_word_is_japan\": True or \"current_word\": \"Japan\"\n",
    "    @context : str : The previous context in the sentence\n",
    "    @current_word : str : The current word to be predicted (the next word of the context, not included in @context)\n",
    "    Returns: dict : A dictionary of features\n",
    "    \"\"\"\n",
    "    def _extract_features(self, context, current_word, n=10):\n",
    "        features = {}\n",
    "        \n",
    "        # Your code here\n",
    "        top_words = self.lm.next_word_ranking(context, n)\n",
    "        \n",
    "        for word, _ in top_words:\n",
    "            features[f\"{word}_in_next_word\"] = True\n",
    "\n",
    "        features[\"current_word\"] = current_word.lower()\n",
    "        return features\n",
    "\n",
    "    \"\"\"\n",
    "    TODO: fill some of the missing pieces.\n",
    "    Predicts the named entities in the given sentence.\n",
    "    @sentence : str : An input sentence for NER tagging\n",
    "    Returns: list : A list of tuples containing the word and its predicted NER tag\n",
    "    \"\"\"\n",
    "    def predict(self, sentence):\n",
    "        self.train()\n",
    "        words = self.lm.tokenize(sentence)\n",
    "        tags = []\n",
    "\n",
    "        for i in range(len(words)):\n",
    "            context = \"\" if i < 3 else f\"{words[i-2]} {words[i-1]}\"\n",
    "            current_word = words[i]\n",
    "            feature = self._extract_features(context, current_word)\n",
    "            tag = self.model.predict([feature])[0]\n",
    "            tags.append((current_word, tag))\n",
    "\n",
    "        return tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K7L8gC2dGpj-"
   },
   "source": [
    "## Task 3: Self Evaluation\n",
    "\n",
    "Congratulations! You have completed all parts that are actually implementing the models. Now you need to do some testing to check if your implementation is correct.\n",
    "\n",
    "Your implemented LM or tagger may not be very high-performing because of the limitations in model sizes and data sizes. There is no need to try to improve model performances as long as the basic implementation is correct. You will not receive any extra credit by improving the models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "umxl4Ec2awZ_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab loaded, size = 26997\n",
      "corpus loaded, size = 57340\n"
     ]
    }
   ],
   "source": [
    "# train language model and tagger\n",
    "lm = TrigramLM(\"vocab.txt\")\n",
    "lm.train()\n",
    "ner_tagger = NERTagger(lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "XGWWz5K0Svt7"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "You MUST not modify any of the functions in this section, except self_evaluate().\n",
    "DANGER: Modifying anything outside of self_evaluate will lead to an automatic zero for this assignment.\n",
    "'''\n",
    "def make_prediction_lm(lm, data):\n",
    "    predictions = []\n",
    "    for context in data:\n",
    "        pred = lm.next_word_ranking(context)\n",
    "        if len(pred) == 0:\n",
    "            pred = []\n",
    "        else:\n",
    "            pred = [x[0] for x in pred]\n",
    "        predictions.append(pred)\n",
    "    return predictions\n",
    "\n",
    "def make_prediction_tagger(tagger, text):\n",
    "    pred = ner_tagger.predict(text)\n",
    "    return [d[1] for d in pred]\n",
    "\n",
    "# load eval news articles\n",
    "def load_eval_news_data():\n",
    "    texts = []\n",
    "    with open(\"eval_news.txt\", \"r\") as f:\n",
    "        for line in f:\n",
    "            texts.append(line.strip())\n",
    "    data = []\n",
    "    # tokenize and create a list of contexts\n",
    "    for text in texts:\n",
    "        tokens = word_tokenize(text.lower())\n",
    "        for i in range(2, len(tokens)):\n",
    "            context = \" \".join(tokens[:i])\n",
    "            data.append(context)\n",
    "    print(f\"data len = {len(data)}\")\n",
    "    return data\n",
    "\n",
    "# run lm and tagger and generate prediction files.\n",
    "def evaluate(lm, tagger):\n",
    "    # evaluate lm\n",
    "    pred_lm = make_prediction_lm(lm, load_eval_news_data())\n",
    "    with open(\"lm_predictions.txt\", \"w\") as f:\n",
    "        for pred in pred_lm:\n",
    "            f.write(\" \".join(pred) + \"\\n\")\n",
    "\n",
    "    # evaluate tagger\n",
    "    eval_ner_data = load_conll2003(\"test\")[:200]\n",
    "    text = \" \".join([x[0] for x in eval_ner_data])\n",
    "    pred_ner = make_prediction_tagger(tagger, text)\n",
    "    with open(\"ner_predictions.txt\", \"w\") as f:\n",
    "        for pred in pred_ner:\n",
    "            f.write(pred + \"\\n\")\n",
    "\n",
    "'''\n",
    "Feel free to modify this part to check if your lm and NER tagger are doing the right thing.\n",
    "Note that this part will not be graded.\n",
    "'''\n",
    "def self_evaluate(lm, tagger):\n",
    "    # evaluate lm on toy data\n",
    "    pred_lm = make_prediction_lm(lm, [\"A\", \"A student\", \"A student at\"])\n",
    "    # expected output\n",
    "    labl_lm = [['<UNK>', 'few', 'man', 'new', 'second', 'number', 'good', 'little', 'third', 'couple'],\n",
    "            ['at', 'council', 'in', 'orator', 'was', 'of', 'you', 'organization', 'who', 'to'],\n",
    "            ['the', '<UNK>', 'georgia', 'arms', 'harvard', 'brown']]\n",
    "    assert len(pred_lm) == len(labl_lm)\n",
    "    for i in range(3):\n",
    "        print(pred_lm[i])\n",
    "        print(labl_lm[i])\n",
    "        #assert pred_lm[i] == labl_lm[i]\n",
    "\n",
    "    # evaluate ner tagger\n",
    "    pred_tagger = make_prediction_tagger(tagger, \"Jeff lives in Japan\")\n",
    "    # expected output\n",
    "    labl_tagger = ['B-PER', 'O', 'O', 'B-LOC']\n",
    "    # assert pred_tagger == labl_tagger\n",
    "    print(\"pred_tagger: \" + str(pred_tagger) + \"\\nlabl_tagger: \" + str(labl_tagger))\n",
    "    print(\"self evaluation passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "v5WhJQoEq22i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<UNK>', 'few', 'man', 'second', 'new', 'number', 'good', 'third', 'little', 'year']\n",
      "['<UNK>', 'few', 'man', 'new', 'second', 'number', 'good', 'little', 'third', 'couple']\n",
      "['at', 'you', 'who', 'was', 'to', 'telling', 'organization', 'orator', 'of', 'manager']\n",
      "['at', 'council', 'in', 'orator', 'was', 'of', 'you', 'organization', 'who', 'to']\n",
      "['the', 'harvard', 'georgia', 'brown', 'arms', '<UNK>', '}', '{', 'zworykin', 'zurich']\n",
      "['the', '<UNK>', 'georgia', 'arms', 'harvard', 'brown']\n",
      "[Pipeline] .... (step 1 of 2) Processing dictvectorizer, total=   0.0s\n",
      "[Pipeline] ........ (step 2 of 2) Processing perceptron, total=   0.1s\n",
      "pred_tagger: [np.str_('O'), np.str_('O'), np.str_('O'), np.str_('B-LOC')]\n",
      "labl_tagger: ['B-PER', 'O', 'O', 'B-LOC']\n",
      "self evaluation passed!\n"
     ]
    }
   ],
   "source": [
    "# self evaluate\n",
    "self_evaluate(lm, ner_tagger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VM2XiMWbIBLf"
   },
   "source": [
    "The final step is to run the evaluate() function below to generate lm_predictions.txt and ner_predictions.txt. These two files will need to be submitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "u_3ayNE6S1Zh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data len = 203\n",
      "[Pipeline] .... (step 1 of 2) Processing dictvectorizer, total=   0.1s\n",
      "[Pipeline] ........ (step 2 of 2) Processing perceptron, total=   0.1s\n"
     ]
    }
   ],
   "source": [
    "# generate prediction files\n",
    "evaluate(lm, ner_tagger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-OYilaMZIJTe"
   },
   "source": [
    "## Final Question\n",
    "Is accuracy a good metric for NER? Why and why not? What other metric should we use to better evaluate model performances? Write your response below.\n",
    "\n",
    "Accuracy is not the best metric for measuring NER quality. While evaluating accuracy the model faces problems of class imbalance (majority of tokens in datasets are labled as 'O') and poor performance on partial matching (for example, classifying B-PER but failing to recognize I-PER should result in the entire failure on the entity). \n",
    "It may be more productive to compute precision (if we are interested in the recognition on a particular class), recall (identifying all entites of a particular class) or f1-score.\n",
    "\n",
    "## Final Submission\n",
    "Please answer the final question above and submit the completed notebook with intermediate runnning logs, as well as lm_predictions.txt and ner_predictions.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
